# -*- coding: utf-8 -*-
"""working_draft.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1df0zI13Zi3cKNNysRpCnZaAWLNaxqDfp

DO NOT WRITE ANY DETAILED CODE (JUST YET!) WE ARE JUST WRITING PSEDUOCODE.
Write your name at the top of what you write, if you are editing something someone else wrote, add it with a # and then your name and comments.

1. Load data
2. Clean/split data (80/20)
3. Build regression model
  * What tornado classifications are there?
  * Does a tornado even form?
  * Can we tell what station/location it is detected at?
4. Test model
  * Are we getting a result?
  * Is it accurate?
5. Analyze results
  *   False/True Positive/Negative
"""

"""
Penelope
https://www.geeksforgeeks.org/python-linear-regression-using-sklearn/
https://www.geeksforgeeks.org/python-linear-regression-using-sklearn/?ref=ml_lbp
"""
#load a bunch of libraries

#open/read dataset

#plot a few scatter plots to see what would make the most sense to find a relationship to
#use grouping method prof talked about in class

#choose x and y variables/groupings

#clean NaN values, restrict to 80/20

#train model
  #independent/dependent variables
  #numpy array
  #1 column

#plot and see results

#use smaller testing dataset (20%)

#evaluate regression metrics (mean squared error)

import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# import whatever else later

df=pd.read_csv("tornadocsv.csv")

df.head()

len(df)

df=df.dropna()

df['Tornado_ID'] = range(1, len(df) + 1)

from datetime import datetime

df['ZTIME'] = df['ZTIME'].str.split(' ').str[0]

# Parse ZTIME to extract the date and calculate days since the start of the year to make time numerical
reference_date = datetime(2024, 1, 1)

def ztime_to_days(ztime):
    try:
        return (datetime.strptime(ztime.split(' ')[0], '%m/%d/%Y') - reference_date).days
    except Exception:
        return None

df['Days_Since_Ref'] = df['ZTIME'].apply(ztime_to_days)

numeric_columns = ['RANGE', 'AZIMUTH', 'MAX_SHEAR', 'MXDV', 'LAT', 'LON', 'Days_Since_Ref']
data_numeric = df[numeric_columns]

scaler = StandardScaler()
# Apply scaling only to the numeric columns
data_scaled = scaler.fit_transform(data_numeric)

inertia_values = []
for k in range(1, 30):
    kmeans = KMeans(n_clusters=k)
    kmeans.fit(data_scaled)
    inertia_values.append(kmeans.inertia_)
print(inertia_values)

plt.figure(figsize=(10,6))
plt.plot(range(1,30),inertia_values, marker= "o", color="red")
plt.title('K-Means')
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')
plt.grid(True)
plt.show()

kmeans=KMeans(n_clusters=5) # we can change this later im just guessing #penny- i changed it to 5 bc thats when the distance really starts being uniform

cluster_labels=kmeans.fit_predict(data_scaled)

# Convert data_scaled back to a Pandas DataFrame
data_scaled = pd.DataFrame(data_scaled, columns=numeric_columns)

# Now you can assign the cluster labels to a new column
data_scaled["cluster"] = cluster_labels

grouped=data_scaled.groupby("cluster")

for cluster, group in grouped:
    print(f"\ncluster {cluster}")
    sample_tornado= group.sample(n=5).index
    for tornado in sample_tornado:
        print(tornado)

#penelope
import seaborn as sns

data_numeric_filtered = data_scaled.drop(columns=["LAT", "LON"]) #deleted for this bc im not sure it can be part of the final bc time
grouped_filtered = data_numeric_filtered.groupby("cluster")
cluster_summary_filtered = grouped_filtered.agg(["mean", "std"])

means_filtered = cluster_summary_filtered.xs('mean', axis=1, level=1)
stds_filtered = cluster_summary_filtered.xs('std', axis=1, level=1)

#mean and standard deviation is there ready to be made into a graph or other data visualization :)

#data visualization (I am doing 2 so we can choose whichever is better)

# Heatmap of cluster means
plt.figure(figsize=(12, 8))
sns.heatmap(means_filtered.T, annot=True, fmt=".2f", cmap="coolwarm")
plt.title("Cluster Feature Means")
plt.xlabel("Clusters")
plt.ylabel("Features")
plt.show()

# Bar plot
stds_filtered.T.plot(kind='bar', figsize=(14, 8))
plt.title("Feature Standard Deviations by Cluster")
plt.xlabel("Features")
plt.ylabel("Standard Deviation")
plt.legend(title="Clusters", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()